{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-BeGLmld1AmJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mn4J9seqTWxM",
        "outputId": "bfd2e3af-d6db-4503-f1ba-db72394f8a66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bertopic[all]\n",
            "  Downloading bertopic-0.17.3-py3-none-any.whl.metadata (24 kB)\n",
            "\u001b[33mWARNING: bertopic 0.17.3 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: hdbscan>=0.8.29 in /usr/local/lib/python3.12/dist-packages (from bertopic[all]) (0.8.40)\n",
            "Requirement already satisfied: umap-learn>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from bertopic[all]) (0.5.9.post2)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.12/dist-packages (from bertopic[all]) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.12/dist-packages (from bertopic[all]) (2.2.2)\n",
            "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from bertopic[all]) (5.24.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.12/dist-packages (from bertopic[all]) (1.6.1)\n",
            "Requirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from bertopic[all]) (5.1.1)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.12/dist-packages (from bertopic[all]) (4.67.1)\n",
            "Requirement already satisfied: llvmlite>0.36.0 in /usr/local/lib/python3.12/dist-packages (from bertopic[all]) (0.43.0)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.12/dist-packages (from hdbscan>=0.8.29->bertopic[all]) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from hdbscan>=0.8.29->bertopic[all]) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.5->bertopic[all]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.5->bertopic[all]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.5->bertopic[all]) (2025.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly>=4.7.0->bertopic[all]) (8.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from plotly>=4.7.0->bertopic[all]) (25.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0->bertopic[all]) (3.6.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=0.4.1->bertopic[all]) (4.57.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=0.4.1->bertopic[all]) (2.8.0+cu126)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=0.4.1->bertopic[all]) (0.35.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=0.4.1->bertopic[all]) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=0.4.1->bertopic[all]) (4.15.0)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.12/dist-packages (from umap-learn>=0.5.0->bertopic[all]) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.12/dist-packages (from umap-learn>=0.5.0->bertopic[all]) (0.5.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[all]) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[all]) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[all]) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[all]) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[all]) (1.1.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic[all]) (1.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic[all]) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic[all]) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic[all]) (0.6.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic[all]) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[all]) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[all]) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[all]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic[all]) (2025.10.5)\n",
            "Downloading bertopic-0.17.3-py3-none-any.whl (153 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bertopic\n",
            "Successfully installed bertopic-0.17.3\n"
          ]
        }
      ],
      "source": [
        "!pip install bertopic[all]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NBEpkdD7zCrh",
        "outputId": "8e4aaefe-46c3-4087-e7e2-44683b378ffd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-1.0.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting langchain-core<2.0.0,>=1.0.0 (from langchain_openai)\n",
            "  Downloading langchain_core-1.0.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.12.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_openai) (0.4.37)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_openai) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_openai) (2.11.10)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_openai) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_openai) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_openai) (4.15.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain_openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain_openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain_openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain_openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain_openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_openai) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_openai) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain_openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.0->langchain_openai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain_openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain_openai) (2.5.0)\n",
            "Downloading langchain_openai-1.0.1-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.0.0-py3-none-any.whl (467 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.2/467.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-core, langchain_openai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.79\n",
            "    Uninstalling langchain-core-0.3.79:\n",
            "      Successfully uninstalled langchain-core-0.3.79\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-core-1.0.0 langchain_openai-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Any, Optional, Tuple\n",
        "import numpy as np, pandas as pd, math\n",
        "from tqdm import tqdm\n",
        "from umap import UMAP\n",
        "import openai\n",
        "import nltk\n",
        "import time\n",
        "import os\n",
        "import re\n",
        "import unicodedata\n",
        "import copy\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from hdbscan import HDBSCAN\n",
        "from bertopic import BERTopic\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from bertopic.representation import OpenAI\n",
        "from openai import OpenAI as OpenAIClient\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import KMeans\n",
        "from collections import Counter\n",
        "from google.colab import userdata\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from scipy.spatial.distance import pdist\n",
        "from scipy.cluster.hierarchy import linkage, fcluster\n",
        "from itertools import product"
      ],
      "metadata": {
        "id": "WUQ_FlY8gBSf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7af7f6de-b571-4403-db8b-4c7f7ea7488b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/hdbscan/robust_single_linkage_.py:175: SyntaxWarning: invalid escape sequence '\\{'\n",
            "  $max \\{ core_k(a), core_k(b), 1/\\alpha d(a,b) \\}$.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 토크나이저 불용어 정의"
      ],
      "metadata": {
        "id": "y-SQ25ZnqyFh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DyB7Vl1dAc9"
      },
      "outputs": [],
      "source": [
        "bertopic_stopwords = [\n",
        "    # --- 특허 형식어 및 관용구 ---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiAXCLoFRA0K"
      },
      "outputs": [],
      "source": [
        "open_ai_key=userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 전처리 코드"
      ],
      "metadata": {
        "id": "_1KYcw_mqg0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 최초 1회만 필요 ---\n",
        "nltk.download(\"punkt\"); nltk.download(\"stopwords\")\n",
        "nltk.download('punkt_tab')\n",
        "# =========================\n",
        "# 불용어 세트 (언어+도메인)\n",
        "# =========================\n",
        "\n",
        "# 도메인(저신호 구조·형상/부품 일반명사)\n",
        "DOMAIN_STOP = {\n",
        "    \"refrigerator\",\"body\",\"box\",\"lid\",\"plate\",\"rack\",\"space\",\n",
        "    \"assembly\",\"assemblies\",\"housing\",\"housings\",\"case\",\"cases\",\"compartment\",\"compartments\",\n",
        "    \"chamber\",\"chambers\",\"container\",\"containers\",\"shelf\",\"shelves\",\"drawer\",\"drawers\",\n",
        "    \"bin\",\"bins\",\"basket\",\"baskets\",\"tray\",\"trays\",\"partition\",\"partitions\",\"panel\",\"panels\",\n",
        "    \"cover\",\"covers\",\"frame\",\"frames\",\"bracket\",\"brackets\",\"guide\",\"guides\",\"groove\",\"grooves\",\n",
        "    \"opening\",\"openings\",\"closure\",\"closures\",\"hinge\",\"hinges\",\"handle\",\"handles\",\"support\",\"supports\",\n",
        "    \"member\",\"element\",\"component\",\"structure\",\"mechanism\",\"unit\",\"modules\",\"apparatus\",\"device\",\n",
        "    \"storage\",\"control\",\"controller\",\"controllers\",\"position\",\n",
        "\n",
        "    # 배관/유로 주변 저신호\n",
        "    \"evaporator\",\"evaporators\",\"condenser\",\"condensers\",\"compressor\",\"compressors\",\n",
        "    \"fan\",\"fans\",\"blower\",\"blowers\",\"duct\",\"ducts\",\"nozzle\",\"nozzles\",\n",
        "    \"tube\",\"tubes\",\"pipe\",\"pipes\",\"conduit\",\"conduits\",\"manifold\",\"manifolds\",\n",
        "    \"aperture\",\"apertures\",\"edge\",\"edges\",\"corner\",\"corners\",\"sidewall\",\"sidewalls\",\n",
        "\n",
        "    # 의미 희석 일반어\n",
        "    \"composition\",\"agent\",\"parts\",\"weight\",\"mass\",\"type\",\"sample\"\n",
        "}\n",
        "\n",
        "ALL_STOP = DOMAIN_STOP\n",
        "\n",
        "# =========================\n",
        "# 정규표현식 (라벨/단위/형식 제거)\n",
        "# =========================\n",
        "_RE_PATENT_NUM   = re.compile(r'\\b(?:us|wo|kr|ep|jp|cn)\\s*\\d+[a-z]*\\d*\\b', re.I)\n",
        "_RE_CLAIM_EN     = re.compile(r'\\b(claim|claims)\\s*\\d+\\b', re.I)\n",
        "_RE_CLAIM_KO     = re.compile(r'제\\s*\\d+\\s*항')\n",
        "_RE_FIG          = re.compile(r'(?:fig\\.?|figure|도)\\s*\\d+[a-z]*', re.I)\n",
        "_RE_TABLE        = re.compile(r'table\\s*\\d+', re.I)\n",
        "_RE_EXAMPLE_HDR  = re.compile(r'\\b(ex|example|examples)\\s*\\d+[a-z]*\\b', re.I)\n",
        "\n",
        "# 국문 섹션 헤더(샘플 반영)\n",
        "_RE_SECTION_HDR_KO = re.compile(\n",
        "    r'(발명의\\s*분야|기술\\s*분야|배경\\s*기술|발명의\\s*요약|과제|해결수단|효과|도면의\\s*간단한\\s*설명|'\n",
        "    r'발명의\\s*상세한\\s*설명|목적)\\b'\n",
        ")\n",
        "\n",
        "# “것을 특징으로 하는/한다/한다.” 관용구 컷\n",
        "_RE_FEATURE_PHRASE = re.compile(r'것을\\s*특징으로\\s*하는(?:\\s*것)?', re.I)\n",
        "\n",
        "# 참조라벨(12a, b1, 3v 등)\n",
        "_RE_REF_LABEL    = re.compile(r'\\b(?:[a-z]{1,3}\\d{1,4}|\\d{1,4}[a-z]{1,3})\\b', re.I)\n",
        "\n",
        "# 수치-단위/범위/백분표기\n",
        "_RE_NUM_UNIT     = re.compile(r'\\b-?\\d+(?:\\.\\d+)?\\s*(?:nm|mm|cm|μm|um|kg|g|mg|l|ml|rpm|hz|khz|mhz|ghz|db|v|kv|ma|a|w|kw|wh|ppm|bar|psi|kpa|pa|°c|℃|°f|℉|%)\\b', re.I)\n",
        "_RE_WT_VOL_MOL   = re.compile(r'\\b(?:wt|vol|mol)\\.?\\s*%\\b', re.I)\n",
        "_RE_RANGE        = re.compile(r'\\b-?\\d+(?:\\.\\d+)?\\s*(?:~|–|—|-|to)\\s*-?\\d+(?:\\.\\d+)?\\s*(?:%|ppm)?\\b', re.I)\n",
        "\n",
        "# 특수기호 + (10), (12a)류\n",
        "_RE_SYMBOLS      = re.compile(r'[±≤≥≦≧≈∼~×™®©•·…§†º‡°‰℃℉µΩΔαβγμΩ※]')\n",
        "_RE_PAREN_NUM    = re.compile(r'\\(\\s*\\d{1,3}[a-z]?\\s*\\)')\n",
        "\n",
        "_RE_DIGIT = re.compile(r'\\d+')\n",
        "\n",
        "_RE_CLAIM_KO_INLINE = re.compile(\n",
        "    r'(?:청구항\\s*\\d+(?:\\s*(?:[,~–—\\-]|내지|및|또는)\\s*\\d+)*)'\n",
        "    r'|(?:제\\s*\\d+\\s*항(?:\\s*(?:[,~–—\\-]|내지|및|또는)\\s*제?\\s*\\d+\\s*항)*)',\n",
        "    re.I\n",
        ")\n",
        "_RE_INLINE_FORMULA = re.compile(\n",
        "    r'(?:\\|[^\\|>]+>\\s*(?:=|\\+|-|\\*|/)?\\s*)+'   # |ψ>, |0>, |1>, |+> 등 브라켓 ket 기호\n",
        "    r'|(?:[α-ωΑ-Ω]\\s*(?:=|\\+|-|\\*|/)?\\s*)+'    # 그리스 문자 α, β, ψ, Ω 등\n",
        "    r'|(?:[A-Za-z]\\s*=\\s*[^,;\\n]+)',           # 단일 문자 = 식 (예: x = y+z)\n",
        "    re.UNICODE\n",
        ")\n",
        "\n",
        "# 문제되는 빅그램(원하면 추가)\n",
        "_RE_PHRASES = [\n",
        "    re.compile(r'\\bheat\\s+exchanger\\b', re.I),\n",
        "    re.compile(r'\\bkimchi\\s+refrigerator\\b', re.I),\n",
        "]\n",
        "\n",
        "def _normalize(text: str) -> str:\n",
        "    t = unicodedata.normalize(\"NFKC\", text).lower()\n",
        "    # 하이픈/슬래시 제외 특수문자 제거\n",
        "    t = re.sub(r\"[^\\w\\s\\-/]\", \" \", t)\n",
        "    return t\n",
        "\n",
        "def simple_preprocess_for_embedding(texts: list[str]) -> list[str]:\n",
        "    \"\"\"\n",
        "    임베딩 전처리(업데이트):\n",
        "      - 한국어 특허 보일러플레이트/형식어, 위치어, 조작 일반어 대폭 확장\n",
        "      - 국문 섹션 헤더/관용구(‘것을 특징으로 하는’) 제거\n",
        "      - 특허번호/도면/라벨/단위/범위/특수기호 제거\n",
        "    \"\"\"\n",
        "    out = []\n",
        "    for text in texts:\n",
        "        if not isinstance(text, str) or not text.strip():\n",
        "            out.append(\"\")\n",
        "            continue\n",
        "\n",
        "        t = _normalize(text)\n",
        "\n",
        "        # 형식/헤더/참조\n",
        "        t = _RE_PATENT_NUM.sub(\" \", t)\n",
        "        t = _RE_CLAIM_EN.sub(\" \", t); t = _RE_CLAIM_KO.sub(\" \", t)\n",
        "        t = _RE_FIG.sub(\" \", t); t = _RE_TABLE.sub(\" \", t); t = _RE_EXAMPLE_HDR.sub(\" \", t)\n",
        "        t = _RE_SECTION_HDR_KO.sub(\" \", t)\n",
        "        t = _RE_FEATURE_PHRASE.sub(\" \", t)\n",
        "\n",
        "        # 라벨/숫자-단위/범위/기호\n",
        "        t = _RE_REF_LABEL.sub(\" \", t)\n",
        "        t = _RE_PAREN_NUM.sub(\" \", t)\n",
        "        t = _RE_RANGE.sub(\" \", t)\n",
        "        t = _RE_WT_VOL_MOL.sub(\" \", t)\n",
        "        t = _RE_NUM_UNIT.sub(\" \", t)\n",
        "        t = _RE_SYMBOLS.sub(\" \", t)\n",
        "        t = _RE_CLAIM_KO_INLINE.sub(' ', t)\n",
        "        t = _RE_DIGIT.sub(' ', t)\n",
        "        t = _RE_INLINE_FORMULA.sub(' ', t)\n",
        "\n",
        "        # 빅그램 제거(옵션)\n",
        "        for pat in _RE_PHRASES:\n",
        "            t = pat.sub(\" \", t)\n",
        "\n",
        "        # 공백 정리\n",
        "        t = re.sub(r\"\\s+\", \" \", t).strip()\n",
        "\n",
        "        # 토큰화 후 불용어/숫자/1글자 제거|\n",
        "        toks = word_tokenize(t)\n",
        "        toks = [w for w in toks if w not in ALL_STOP and len(w) > 1 and not w.isdigit()]\n",
        "\n",
        "        out.append(\" \".join(toks))\n",
        "    return out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrQ7a4qdTUq6",
        "outputId": "131b6a00-7e0e-4f16-8b62-b2d4b65b7274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijaLcw0ifd5i"
      },
      "outputs": [],
      "source": [
        "#임베딩 함수\n",
        "client = OpenAIClient(api_key=open_ai_key)\n",
        "\n",
        "embedding_model = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-3-small\",\n",
        "    api_key=open_ai_key\n",
        ")\n",
        "\n",
        "representation_model = OpenAI(\n",
        "    client = client,\n",
        "    model=\"gpt-4.1-mini\",\n",
        "    api_key=open_ai_key,\n",
        "    verbose=True,\n",
        "    chat=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44Ba1ZnafZir"
      },
      "outputs": [],
      "source": [
        "#배치 처리로 문서 임베딩 생성 (tqdm 적용)\n",
        "def create_embeddings_with_progress(docs, batch_size=100):\n",
        "    embeddings = []\n",
        "\n",
        "    # 전체 배치 수 계산\n",
        "    total_batches = (len(docs) + batch_size - 1) // batch_size\n",
        "\n",
        "    with tqdm(total=total_batches, desc=\"Creating embeddings\") as pbar:\n",
        "        for i in range(0, len(docs), batch_size):\n",
        "            batch = docs[i:i+batch_size]\n",
        "            batch_embeddings = embedding_model.embed_documents(batch)\n",
        "            embeddings.extend(batch_embeddings)\n",
        "\n",
        "            # 진행률 업데이트\n",
        "            pbar.set_postfix({\n",
        "                'Processed': f\"{min(i+batch_size, len(docs))}/{len(docs)} docs\"\n",
        "            })\n",
        "            pbar.update(1)\n",
        "\n",
        "    return np.array(embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 함수 정의"
      ],
      "metadata": {
        "id": "0HR2Acl5U65o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_EXTRA_STOP = [\"placeholdertoken\"]\n",
        "\n",
        "# 2) 한글 2자+ 또는 대문자 약어 3자+만 허용(1글자/숫자 단독 컷)\n",
        "_TOKEN_RE = re.compile(r\"[가-힣]{2,}|[A-Z]{3,}(?:-[A-Z0-9]+)*\")\n",
        "\n",
        "\n",
        "def _ko_simple_analyzer(doc: str):\n",
        "    if not isinstance(doc, str):\n",
        "        return []\n",
        "    toks = _TOKEN_RE.findall(doc)\n",
        "    # 숫자만 / 소문자 1~2자 방지\n",
        "    out = []\n",
        "    for t in toks:\n",
        "        if re.fullmatch(r\"\\d+(\\.\\d+)?\", t):\n",
        "            continue\n",
        "        if re.fullmatch(r\"[a-z]{1,2}\", t):\n",
        "            continue\n",
        "        out.append(t)\n",
        "    return out"
      ],
      "metadata": {
        "id": "UPClmRRXg5Pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _build_vectorizer(min_df: int = 2):\n",
        "    # 한글/영문/숫자 모두 허용되도록 바운더리 완화\n",
        "    return CountVectorizer(\n",
        "        max_df=0.95,\n",
        "        min_df=2,                     # ← 전달받은 인자 사용\n",
        "        stop_words=bertopic_stopwords,\n",
        "        ngram_range=(1, 1),\n",
        "        token_pattern=r\"(?u)[\\w\\-]+\",\n",
        "        strip_accents='unicode',\n",
        "        lowercase=True\n",
        "    )"
      ],
      "metadata": {
        "id": "wGBqHi3lOjje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#최적의 파라미터 세팅 함수\n",
        "\n",
        "def rescale_params_for_full_run(\n",
        "    N: int,\n",
        "    best,\n",
        "    umap_used,\n",
        "    target_K: int = 120,\n",
        "    mode: str = \"balance\"  # 유지하되, 이제 동작에는 영향 없음(호환 목적)\n",
        "):\n",
        "    \"\"\"\n",
        "    샘플 그리드서치에서 고른 UMAP은 '그대로' 유지(freeze).\n",
        "    풀런 크기 N에 맞춰 HDBSCAN만 스케일링.\n",
        "    \"\"\"\n",
        "    umap_new = dict(umap_used) if umap_used else {}\n",
        "    umap_new.setdefault(\"n_neighbors\", 60)\n",
        "    umap_new.setdefault(\"min_dist\", 0.10)\n",
        "    umap_new.setdefault(\"n_components\", max(umap_new.get(\"n_components\", 10), 10))\n",
        "    umap_new.setdefault(\"metric\", \"cosine\")\n",
        "    umap_new.setdefault(\"random_state\", 42)\n",
        "    # n_neighbors < n_samples 제약 캡핑\n",
        "    n = max(1, N)\n",
        "    umap_new[\"n_neighbors\"] = min(umap_new[\"n_neighbors\"], max(2, n - 1))\n",
        "\n",
        "    # target_size는 K를 과도하게 늘리지 않도록 하는 '하한' 가드\n",
        "    target_size = max(40, int(N / max(10, target_K)))\n",
        "    mcs = int(best.get(\"min_cluster_size\", 50) or 50)\n",
        "    ms  = int(best.get(\"min_samples\", 10) or 10)\n",
        "    eps = float(best.get(\"epsilon\", 0.10))\n",
        "\n",
        "    hdb_new = dict(\n",
        "        min_cluster_size=mcs,\n",
        "        min_samples=ms,\n",
        "        cluster_selection_epsilon=eps,\n",
        "        cluster_selection_method=best.get(\"cluster_selection_method\", \"eom\"),\n",
        "        metric=\"euclidean\",\n",
        "        prediction_data=False,\n",
        "    )\n",
        "    return umap_new, hdb_new"
      ],
      "metadata": {
        "id": "fNnc4xBXYVQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#평가지표 함수\n",
        "\n",
        "def _normalize_docs(docs: List[Any]) -> List[str]:\n",
        "    out = []\n",
        "    for x in docs:\n",
        "        if x is None: out.append(\"\")\n",
        "        elif isinstance(x, str): out.append(x)\n",
        "        elif isinstance(x, (list, tuple)): out.append(\" \".join(map(str, x)))\n",
        "        else: out.append(str(x))\n",
        "    return out\n",
        "\n",
        "def _sanitize_docs_for_vectorizer(docs: List[str]) -> List[str]:\n",
        "    \"\"\"완전 공백 문서 방지용 placeholder 처리.\"\"\"\n",
        "    out = []\n",
        "    for d in docs:\n",
        "        s = (d or \"\").strip()\n",
        "        out.append(s if s else \"placeholdertoken\")\n",
        "    return out\n",
        "\n",
        "def _sample_pair(docs: List[str], emb: np.ndarray, k: int = 1000, seed: int = 42):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    k = min(k, len(docs))\n",
        "    idx = rng.choice(len(docs), size=k, replace=False) if k>0 else np.array([], dtype=int)\n",
        "    return [docs[i] for i in idx], emb[idx], idx\n",
        "\n",
        "def _safe_entropy(counts: np.ndarray) -> float:\n",
        "    s = counts.sum()\n",
        "    if s <= 0: return 0.0\n",
        "    p = counts / s; p = p[p>0]\n",
        "    return float(-np.sum(p*np.log(p)))\n",
        "\n",
        "def _gini(values: List[int]) -> float:\n",
        "    \"\"\"List/ndarray 모두 안전. 비어있거나 합이 0이면 0.\"\"\"\n",
        "    x = np.asarray(values, dtype=float).ravel()\n",
        "    n = x.size\n",
        "    if n == 0:\n",
        "        return 0.0\n",
        "    s = x.sum()\n",
        "    if s <= 0:\n",
        "        return 0.0\n",
        "    x.sort()\n",
        "    cum = np.cumsum(x)\n",
        "    # 0=균등, 1=극단\n",
        "    return float((n + 1 - 2 * np.sum(cum) / s) / n)\n",
        "\n",
        "#outlier_ratio : 노이즈 비율\n",
        "#gini_clean : 지니계수 토픽분포 불균등도 계산\n",
        "#top1_clean : 가장 큰 토픽이 차지하는 비율\n",
        "#n_topics_clean : 실제 토픽 개수(노이즈 제외)\n",
        "#h_norm : 정규화 엔트로피\n",
        "\n",
        "def _topic_metrics(info: pd.DataFrame) -> Dict[str, Any]:\n",
        "    if info is None or info.empty:\n",
        "        return dict(outlier_ratio=np.nan, gini_clean=np.nan, top1_clean=np.nan,\n",
        "                    n_topics_clean=0, h_norm=np.nan)\n",
        "\n",
        "    total = int(info[\"Count\"].sum())\n",
        "    out_cnt = int(info.loc[info.Topic == -1, \"Count\"].sum()) if (-1 in info.Topic.values) else 0\n",
        "    outlier = (out_cnt / total) if total > 0 else np.nan\n",
        "\n",
        "    clean = info[info.Topic != -1]\n",
        "    if clean.empty:\n",
        "        return dict(outlier_ratio=outlier, gini_clean=np.nan, top1_clean=np.nan,\n",
        "                    n_topics_clean=0, h_norm=np.nan)\n",
        "\n",
        "    counts = np.asarray(clean[\"Count\"].astype(int).values, dtype=float).ravel()\n",
        "    counts_sum = counts.sum()\n",
        "    if counts_sum <= 0:\n",
        "        return dict(outlier_ratio=outlier, gini_clean=0.0, top1_clean=np.nan,\n",
        "                    n_topics_clean=int(len(counts)), h_norm=np.nan)\n",
        "\n",
        "    k = int(len(counts))\n",
        "    p = counts / counts_sum\n",
        "    top1 = float(p.max())\n",
        "\n",
        "    # 정규화 엔트로피\n",
        "    h = float(-np.sum(p * np.log(p)))\n",
        "    h_norm = float(h / (math.log(k) if k > 1 else 1.0))\n",
        "\n",
        "    return dict(outlier_ratio=float(outlier),\n",
        "                gini_clean=_gini(counts),\n",
        "                top1_clean=top1,\n",
        "                n_topics_clean=k,\n",
        "                h_norm=h_norm)\n",
        "\n",
        "# “좋을수록 큰 점수”(연속 가중합)\n",
        "def _score_soft(m: Dict[str, Any]) -> float:\n",
        "    out = m.get(\"outlier_ratio\");   out = 1.0 - float(out) if (out==out) else 0.5\n",
        "    hn  = m.get(\"h_norm\");          hn  = float(hn) if (hn==hn) else 0.5\n",
        "    t1  = m.get(\"top1_clean\");      t1  = float(t1) if (t1==t1) else 0.5\n",
        "    g   = m.get(\"gini_clean\");      g   = float(g) if (g==g) else 0.5\n",
        "    top1_term = 1.0 - max(0.0, t1-0.40)/0.60\n",
        "    top1_term = max(0.0, min(1.0, top1_term))\n",
        "    g_term = 1.0 - max(0.0, min(1.0, g))     # gini 낮을수록 가점\n",
        "    return float(0.35*out + 0.25*hn + 0.25*top1_term + 0.15*g_term)\n"
      ],
      "metadata": {
        "id": "DQsPq9edU4-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================ Grid Search ============================\n",
        "def grid_search_umap_hdbscan_on_sample(\n",
        "    docs: List[str], emb: np.ndarray,\n",
        "    sample_size: int = 1000,\n",
        "    umap_grid: Optional[List[dict]] = None,\n",
        "    mcs_grid: Optional[List[int]] = None,\n",
        "    ms_grid: Optional[List[int]]  = None,\n",
        "    eps_grid: Optional[List[float]] = None,\n",
        "    min_topic_size: int = 10,\n",
        "    seed: int = 42,\n",
        "    # 하드 제약(요청사항)\n",
        "    max_noise: float = 0.10,\n",
        "    max_topics: int = 50,\n",
        "    # 로그\n",
        "    show_progress: bool = True\n",
        ") -> Tuple[Dict[str, Any], pd.DataFrame, dict]:\n",
        "    t0 = time.time()\n",
        "    # 입력 정리\n",
        "    assert len(docs) == emb.shape[0], f\"docs({len(docs)}) != emb({emb.shape[0]})\"\n",
        "    docs = _normalize_docs(docs)\n",
        "    emb  = np.asarray(emb, dtype=np.float32)\n",
        "    emb  = np.nan_to_num(emb, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "    docs_s, emb_s, _ = _sample_pair(docs, emb, k=sample_size, seed=seed)\n",
        "\n",
        "    # 소문서 셋 방어: 토큰 드랍 방지용 min_df 동적 조정\n",
        "    min_df = 1 if max(1, len(docs_s)) < 100 else 2\n",
        "    vec = _build_vectorizer(min_df=min_df)\n",
        "    docs_s_vec = _sanitize_docs_for_vectorizer(docs_s)\n",
        "\n",
        "    n_samp = emb_s.shape[0]\n",
        "\n",
        "    # 기본 그리드\n",
        "    if umap_grid is None:\n",
        "        umap_grid = [\n",
        "            dict(n_neighbors=30, n_components=10, min_dist=0.15, metric=\"cosine\", random_state=seed),\n",
        "        ]\n",
        "    if mcs_grid is None: mcs_grid=[20, 25, 30, 40]\n",
        "    if ms_grid  is None: ms_grid =[6, 8, 10, 12]\n",
        "    if eps_grid is None: eps_grid=[0.05, 0.10, 0.20]\n",
        "\n",
        "    def _cap_umap_params(up: dict, n: int) -> dict:\n",
        "        up2 = dict(up)\n",
        "        # n_neighbors must be < n_samples\n",
        "        if n <= 2:\n",
        "            up2[\"n_neighbors\"] = max(2, n-1) if n > 1 else 2\n",
        "        else:\n",
        "            up2[\"n_neighbors\"] = min(up[\"n_neighbors\"], max(2, n-1))\n",
        "        return up2\n",
        "\n",
        "    # 조합 생성 + 진행률 바\n",
        "    combos = list(product(range(len(umap_grid)), mcs_grid, ms_grid, eps_grid))\n",
        "    pbar = tqdm(combos, desc=\"[GridSearch] UMAP×HDBSCAN (1k)\", ncols=100, disable=not show_progress)\n",
        "\n",
        "    rows, objs = [], []\n",
        "    umap_cache = {}\n",
        "\n",
        "    for ui, mcs, ms, eps in pbar:\n",
        "        base_up = umap_grid[ui]\n",
        "        up = _cap_umap_params(base_up, n_samp)\n",
        "\n",
        "        # UMAP 캐시\n",
        "        if ui not in umap_cache:\n",
        "            try:\n",
        "                umap_cache[ui] = UMAP(**up).fit_transform(emb_s)\n",
        "            except Exception as e:\n",
        "                rows.append(dict(umap_n_neighbors=up.get(\"n_neighbors\"), umap_n_components=up.get(\"n_components\"),\n",
        "                                 umap_min_dist=up.get(\"min_dist\"), min_cluster_size=None, min_samples=None, epsilon=None,\n",
        "                                 outlier_ratio=np.nan, gini_clean=np.nan, top1_clean=np.nan, n_topics_clean=0, h_norm=np.nan,\n",
        "                                 soft_score=-1.0, feas=False, viol=1e9, note=f\"umap_error:{type(e).__name__}:{e}\"))\n",
        "                # 해당 ui로 엮인 모든 조합은 스킵\n",
        "                continue\n",
        "\n",
        "        red = umap_cache[ui]\n",
        "        # 진행 문구 업데이트(선택)\n",
        "        pbar.set_postfix_str(f\"UMAP n={up['n_neighbors']}, mcs={mcs}, ms={ms}, eps={eps}\")\n",
        "\n",
        "        try:\n",
        "            hdb = HDBSCAN(min_cluster_size=mcs, min_samples=ms,\n",
        "                          cluster_selection_epsilon=eps, metric=\"euclidean\", prediction_data=False)\n",
        "            tm = BERTopic(embedding_model=None, umap_model=None, hdbscan_model=hdb,\n",
        "                          min_topic_size=min_topic_size, vectorizer_model=vec, verbose=False)\n",
        "            _t, _ = tm.fit_transform(docs_s_vec, embeddings=red)\n",
        "            info = tm.get_topic_info()\n",
        "            met  = _topic_metrics(info)\n",
        "            soft = _score_soft(met)\n",
        "\n",
        "            # 제약 위반량(0이면 Feasible)\n",
        "            out_v = max(0.0, (met[\"outlier_ratio\"] - max_noise)) if met[\"outlier_ratio\"]==met[\"outlier_ratio\"] else 1.0\n",
        "            k_v   = max(0.0, (met[\"n_topics_clean\"] - max_topics)) if met[\"n_topics_clean\"]==met[\"n_topics_clean\"] else 10.0\n",
        "            viol  = 100.0*out_v + 1.0*k_v  # 노이즈 위반 강벌\n",
        "\n",
        "            rec = dict(\n",
        "                umap_n_neighbors=up[\"n_neighbors\"], umap_n_components=up[\"n_components\"], umap_min_dist=up[\"min_dist\"],\n",
        "                min_cluster_size=mcs, min_samples=ms, epsilon=eps,\n",
        "                **met,\n",
        "                soft_score=soft,\n",
        "                feas=(viol==0.0),\n",
        "                viol=viol,\n",
        "                umap_params=up, model=tm, info=info\n",
        "            )\n",
        "            objs.append(rec)\n",
        "            rows.append({k:v for k,v in rec.items() if k not in (\"model\",\"info\",\"umap_params\")})\n",
        "        except Exception as e:\n",
        "            rows.append(dict(\n",
        "                umap_n_neighbors=up[\"n_neighbors\"], umap_n_components=up[\"n_components\"], umap_min_dist=up[\"min_dist\"],\n",
        "                min_cluster_size=mcs, min_samples=ms, epsilon=eps,\n",
        "                outlier_ratio=np.nan, gini_clean=np.nan, top1_clean=np.nan, n_topics_clean=0, h_norm=np.nan,\n",
        "                soft_score=-1.0, feas=False, viol=1e9, note=f\"hdb_error:{type(e).__name__}:{e}\"\n",
        "            ))\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "\n",
        "    # NaN 채움(정렬 안정화)\n",
        "    if not df.empty:\n",
        "        fill_map = {\n",
        "            \"soft_score\": -1.0,\n",
        "            \"h_norm\": -1.0,\n",
        "            \"n_topics_clean\": 10**9,\n",
        "            \"outlier_ratio\": np.nan,  # 정렬에는 사용 안 하므로 그대로\n",
        "        }\n",
        "        for c, v in fill_map.items():\n",
        "            if c in df.columns:\n",
        "                df[c] = df[c].fillna(v)\n",
        "        if \"feas\" in df.columns:\n",
        "            df[\"feas\"] = df[\"feas\"].fillna(False)\n",
        "\n",
        "    # 랭킹(Feasible → soft_score 내림차순 → h_norm 내림차순 → K 오름차순)\n",
        "    feasible = df[df[\"feas\"]==True].copy() if not df.empty else pd.DataFrame()\n",
        "    if not feasible.empty:\n",
        "        rank = feasible.sort_values(\n",
        "            [\"soft_score\",\"h_norm\",\"n_topics_clean\"], ascending=[False,False,True]\n",
        "        ).reset_index(drop=True)\n",
        "        top = rank.iloc[0].to_dict()\n",
        "        # 객체 매칭\n",
        "        for r in objs:\n",
        "            if (r[\"umap_params\"][\"n_neighbors\"]==top[\"umap_n_neighbors\"] and\n",
        "                r[\"umap_params\"][\"n_components\"]==top[\"umap_n_components\"] and\n",
        "                r[\"umap_params\"][\"min_dist\"]==top[\"umap_min_dist\"] and\n",
        "                r[\"min_cluster_size\"]==top[\"min_cluster_size\"] and\n",
        "                r[\"min_samples\"]==top[\"min_samples\"] and\n",
        "                r[\"epsilon\"]==top[\"epsilon\"]):\n",
        "                if show_progress:\n",
        "                    print(f\"\\n[OK] Feasible found in {time.time()-t0:.1f}s \"\n",
        "                          f\"(noise<{max_noise}, K≤{max_topics})\")\n",
        "                return r, rank, r[\"umap_params\"]\n",
        "\n",
        "    # Feasible 없음 → 위반량 최소(viol 오름차순), 그 다음 soft_score 내림차순\n",
        "    if not df.empty and len(objs)>0:\n",
        "        near = df.sort_values([\"viol\",\"soft_score\",\"h_norm\"], ascending=[True,False,False]).reset_index(drop=True)\n",
        "        top = near.iloc[0].to_dict()\n",
        "        for r in objs:\n",
        "            if (r[\"umap_params\"][\"n_neighbors\"]==top[\"umap_n_neighbors\"] and\n",
        "                r[\"umap_params\"][\"n_components\"]==top[\"umap_n_components\"] and\n",
        "                r[\"umap_params\"][\"min_dist\"]==top[\"umap_min_dist\"] and\n",
        "                r[\"min_cluster_size\"]==top[\"min_cluster_size\"] and\n",
        "                r[\"min_samples\"]==top[\"min_samples\"] and\n",
        "                r[\"epsilon\"]==top[\"epsilon\"]):\n",
        "                if show_progress:\n",
        "                    print(f\"\\n[WARN] No feasible combo. Using closest candidate \"\n",
        "                          f\"(viol={float(top['viol']):.3f}) in {time.time()-t0:.1f}s\")\n",
        "                return r, near, r[\"umap_params\"]\n",
        "\n",
        "    # 전부 에러 → 기본값 폴백\n",
        "    up = dict(n_neighbors=15, n_components=8, min_dist=0.10, metric=\"cosine\", random_state=seed)\n",
        "    try:\n",
        "        red = UMAP(**(lambda p: dict(p, **{\"n_neighbors\": min(max(2, n_samp-1), p[\"n_neighbors\"]) }))(up)).fit_transform(emb_s)\n",
        "        hdb = HDBSCAN(min_cluster_size=50, min_samples=8, cluster_selection_epsilon=0.10, metric=\"euclidean\", prediction_data=False)\n",
        "        tm  = BERTopic(embedding_model=None, umap_model=None, hdbscan_model=hdb,\n",
        "                       min_topic_size=min_topic_size, vectorizer_model=vec, verbose=False)\n",
        "        _t,_ = tm.fit_transform(_sanitize_docs_for_vectorizer(docs_s), embeddings=red)\n",
        "        info = tm.get_topic_info(); met = _topic_metrics(info)\n",
        "\n",
        "        out_v = max(0.0, (met[\"outlier_ratio\"] - max_noise)) if met[\"outlier_ratio\"]==met[\"outlier_ratio\"] else 1.0\n",
        "        k_v   = max(0.0, (met[\"n_topics_clean\"] - max_topics)) if met[\"n_topics_clean\"]==met[\"n_topics_clean\"] else 10.0\n",
        "        viol  = 100.0*out_v + 1.0*k_v\n",
        "\n",
        "        best = dict(umap_params=up, min_cluster_size=50, min_samples=8, epsilon=0.10, model=tm, info=info,\n",
        "                    **met, soft_score=_score_soft(met), feas=(met[\"outlier_ratio\"]<max_noise and met[\"n_topics_clean\"]<=max_topics),\n",
        "                    viol=viol, note=\"fallback\")\n",
        "        rank = pd.DataFrame([{**{k:best.get(k) for k in (\"outlier_ratio\",\"n_topics_clean\",\"h_norm\",\"soft_score\",\"feas\",\"viol\")},\n",
        "                              \"umap_n_neighbors\":up[\"n_neighbors\"], \"umap_n_components\":up[\"n_components\"],\n",
        "                              \"umap_min_dist\":up[\"min_dist\"], \"min_cluster_size\":50, \"min_samples\":8, \"epsilon\":0.10,\n",
        "                              \"note\":\"fallback\"}])\n",
        "        if show_progress:\n",
        "            print(f\"\\n[FALLBACK] All combos failed. Returned default in {time.time()-t0:.1f}s\")\n",
        "        return best, rank, up\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"[FATAL] Grid+Fallback failed: {e}\")\n"
      ],
      "metadata": {
        "id": "icww3ZS5mbsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_full_with_best(\n",
        "    docs: List[str], emb: np.ndarray,\n",
        "    best: Dict[str,Any], umap_used: dict,\n",
        "    min_topic_size: int = 10, verbose: bool = False,\n",
        "    max_noise: float = 0.10, max_topics: int = 50\n",
        ") -> Dict[str, Any]:\n",
        "    docs = _normalize_docs(docs)\n",
        "    docs_vec = _sanitize_docs_for_vectorizer(docs)\n",
        "    emb  = np.asarray(emb, dtype=np.float32)\n",
        "    emb  = np.nan_to_num(emb, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "    # UMAP n_neighbors 제약 캡\n",
        "    def _cap_umap_params(up: dict, n: int) -> dict:\n",
        "        up2 = dict(up)\n",
        "        if n <= 2:\n",
        "            up2[\"n_neighbors\"] = max(2, n-1) if n > 1 else 2\n",
        "        else:\n",
        "            up2[\"n_neighbors\"] = min(up[\"n_neighbors\"], max(2, n-1))\n",
        "        return up2\n",
        "    umap_used = _cap_umap_params(umap_used, emb.shape[0])\n",
        "\n",
        "    # Vectorizer 동적 min_df\n",
        "    min_df = 1 if max(1, len(docs_vec)) < 100 else 2\n",
        "    vec  = _build_vectorizer(min_df=min_df)\n",
        "\n",
        "    N = len(docs)\n",
        "    umap_adj, hdb_adj = rescale_params_for_full_run(N, best, umap_used)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"[FullRun-Scaled] UMAP:\", umap_adj)\n",
        "        print(\"[FullRun-Scaled] HDB :\", hdb_adj)\n",
        "\n",
        "    # UMAP fit\n",
        "    u = UMAP(**umap_adj)\n",
        "    red = u.fit_transform(emb)\n",
        "\n",
        "    # HDBSCAN+BERTopic\n",
        "    hdb = HDBSCAN(**hdb_adj)\n",
        "    tm  = BERTopic(\n",
        "        embedding_model=None, umap_model=None, hdbscan_model=hdb,\n",
        "        min_topic_size=min_topic_size,            # ← 전달 누락 보정\n",
        "        vectorizer_model=vec, verbose=False\n",
        "    )\n",
        "    topics, probs = tm.fit_transform(docs, embeddings=red)\n",
        "    info = tm.get_topic_info()\n",
        "    met = _topic_metrics(info)\n",
        "\n",
        "    feasible = (met[\"outlier_ratio\"] < max_noise) and (met[\"n_topics_clean\"] <= max_topics)\n",
        "    if verbose:\n",
        "        print(f\"[FullRun] Metrics: noise={float(met['outlier_ratio']):.3f}, \"\n",
        "              f\"K={int(met['n_topics_clean'])}, \"\n",
        "              f\"H_norm={(met['h_norm'] if met['h_norm']==met['h_norm'] else float('nan')):.3f} \"\n",
        "              f\"=> FEASIBLE={feasible}\")\n",
        "\n",
        "    return dict(\n",
        "        model=tm, umap=u, topics=topics, probs=probs, info=info,\n",
        "        metrics=met, feasible=feasible,\n",
        "        used_params=dict(umap=umap_adj,                     # ← 실제 사용값 기록\n",
        "                         hdb=dict(min_cluster_size=hdb_adj[\"min_cluster_size\"],\n",
        "                                  min_samples=hdb_adj[\"min_samples\"],\n",
        "                                  epsilon=hdb_adj[\"cluster_selection_epsilon\"]))\n",
        "    )"
      ],
      "metadata": {
        "id": "3b7Q3NjumYAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 메인 파트"
      ],
      "metadata": {
        "id": "6G2_HK3Cqne0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeTaCnLOYHdH"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/압력기반공급제어.xlsx'  # Colab에서는 직접 업로드\n",
        "df_topic = pd.read_excel(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_topic.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oh5j9HzzjrrV",
        "outputId": "74cbed50-8047-43c3-b834-673d53aae228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['출원번호', '국가코드', '발명의 명칭', '대표청구항', '요약', '기술명', '소주제', '점수', '근거', '순서',\n",
              "       '번역'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "category=df_topic['기술군'].unique()"
      ],
      "metadata": {
        "id": "N00oIyk-CQuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in category :\n",
        "\n",
        "    df_topic_temp=df_topic[df_topic['기술군'] == i]\n",
        "    df_list = df_topic_temp['번역'].tolist()\n",
        "    # 불용어 및 전처리\n",
        "    df_list_pro=simple_preprocess_for_embedding(df_list)"
      ],
      "metadata": {
        "id": "TlP9pFScCUQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7vZiWBse261"
      },
      "outputs": [],
      "source": [
        "df_list = df_topic['번역'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "re_DISgZmAnW"
      },
      "outputs": [],
      "source": [
        "# 불용어 및 전처리\n",
        "df_list_pro=simple_preprocess_for_embedding(df_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4e4-TZPB0kj",
        "outputId": "3ad212d8-1a44-461a-efbc-b3f97697eb71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Creating embeddings: 100%|██████████| 8/8 [00:17<00:00,  2.22s/it, Processed=726/726 docs]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Embeddings shape: (726, 1536)\n"
          ]
        }
      ],
      "source": [
        "embeddings = create_embeddings_with_progress(df_list_pro)\n",
        "print(f\"\\n Embeddings shape: {embeddings.shape}\")\n",
        "embeddings = np.array(embeddings)  # 혹시 list이면 array로 변환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDnhplEdasln"
      },
      "outputs": [],
      "source": [
        "# embedding 저장/로드하는 코드\n",
        "# np.save('/content/drive/MyDrive/Patent analysis/ETRI/embeddings_ETRI_양자기술_모집단.npy', embeddings_quantum)\n",
        "# embeddings_quantum=np.load('/content/drive/MyDrive/Patent analysis/ETRI/embeddings_ETRI_양자기술.npy',mmap_mode = 'r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv2bh9WvdOwP",
        "outputId": "21c68489-d5a7-4f65-ecad-8d3628006c79",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[GridSearch] UMAP×HDBSCAN (1k): 100%|█| 48/48 [00:29<00:00,  1.64it/s, UMAP n=30, mcs=40, ms=12, eps\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[OK] Feasible found in 29.3s (noise<0.1, K≤50)\n",
            "   umap_n_neighbors  umap_n_components  umap_min_dist  min_cluster_size  \\\n",
            "0                30                 10           0.15                20   \n",
            "1                30                 10           0.15                20   \n",
            "2                30                 10           0.15                20   \n",
            "3                30                 10           0.15                25   \n",
            "4                30                 10           0.15                20   \n",
            "5                30                 10           0.15                20   \n",
            "6                30                 10           0.15                20   \n",
            "7                30                 10           0.15                20   \n",
            "8                30                 10           0.15                25   \n",
            "9                30                 10           0.15                25   \n",
            "\n",
            "   min_samples  epsilon  outlier_ratio  n_topics_clean    h_norm  soft_score  \\\n",
            "0            6     0.05          0.070               6  0.952788    0.932783   \n",
            "1            6     0.20          0.065               5  0.949368    0.931544   \n",
            "2            8     0.20          0.080               5  0.953284    0.928365   \n",
            "3            8     0.20          0.000               3  0.899776    0.919527   \n",
            "4           10     0.20          0.000               4  0.898943    0.914944   \n",
            "5           12     0.05          0.085               4  0.923435    0.914428   \n",
            "6            6     0.10          0.045               4  0.900198    0.904871   \n",
            "7           12     0.20          0.045               4  0.900198    0.904871   \n",
            "8           12     0.20          0.040               2  0.986731    0.902648   \n",
            "9            6     0.10          0.045               2  0.987606    0.902399   \n",
            "\n",
            "   feas  viol  \n",
            "0  True   0.0  \n",
            "1  True   0.0  \n",
            "2  True   0.0  \n",
            "3  True   0.0  \n",
            "4  True   0.0  \n",
            "5  True   0.0  \n",
            "6  True   0.0  \n",
            "7  True   0.0  \n",
            "8  True   0.0  \n",
            "9  True   0.0  \n",
            "[FullRun-Scaled] UMAP: {'n_neighbors': 30, 'n_components': 10, 'min_dist': 0.15, 'metric': 'cosine', 'random_state': 42}\n",
            "[FullRun-Scaled] HDB : {'min_cluster_size': 20, 'min_samples': 6, 'cluster_selection_epsilon': 0.05, 'cluster_selection_method': 'eom', 'metric': 'euclidean', 'prediction_data': False}\n",
            "[FullRun] Metrics: noise=0.081, K=14, H_norm=0.949 => FEASIBLE=True\n"
          ]
        }
      ],
      "source": [
        "docs = df_list_pro  # List[str]\n",
        "emb  = embeddings   # np.ndarray (N x d)\n",
        "\n",
        "# docs: List[str], emb: np.ndarray\n",
        "best, rank, umap_used = grid_search_umap_hdbscan_on_sample(\n",
        "    docs, emb, sample_size=200, show_progress=True\n",
        ")\n",
        "print(rank.head(10)[[\n",
        "    \"umap_n_neighbors\",\"umap_n_components\",\"umap_min_dist\",\n",
        "    \"min_cluster_size\",\"min_samples\",\"epsilon\",\n",
        "    \"outlier_ratio\",\"n_topics_clean\",\"h_norm\",\"soft_score\",\"feas\",\"viol\"\n",
        "]])\n",
        "\n",
        "full = run_full_with_best(docs, emb, best, umap_used, min_topic_size=10, verbose=True)\n",
        "# full[\"metrics\"], full[\"feasible\"], full[\"used_params\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model = copy.deepcopy(full['model'])"
      ],
      "metadata": {
        "id": "YAMJ2Rd6bPwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full['model'].get_topic_info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "i84vEohv7N2N",
        "outputId": "9bba01d5-989f-4f0a-bb9a-902404871091",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Topic  Count                                         Name  \\\n",
              "0      -1     59             -1_expansion_ti_turbine_transfer   \n",
              "1       0    114                     0_valve_path_second_side   \n",
              "2       1     89           1_accumulator_cell_vehicle_purpose   \n",
              "3       2     68           2_charging_second_transfer_vehicle   \n",
              "4       3     56       3_liquefied_cell_stack_electrochemical   \n",
              "5       4     53                4_value_amount_volume_vehicle   \n",
              "6       5     50      5_accumulator_cylinder_line_refrigerant   \n",
              "7       6     39               6_pump_engine_passage_injector   \n",
              "8       7     38                   7_cell_main_valve_reducing   \n",
              "9       8     34          8_charging_cooling_freezing_charged   \n",
              "10      9     32      9_compression_piston_cylinder_hydraulic   \n",
              "11     10     26         10_information_charging_cooling_step   \n",
              "12     11     25            11_bank_constant_banks_inspection   \n",
              "13     12     22     12_electric_charging_energy_particularly   \n",
              "14     13     21  13_gaseous_cryogenic_liquefied_vaporization   \n",
              "\n",
              "                                       Representation  \\\n",
              "0   [expansion, ti, turbine, transfer, least, valv...   \n",
              "1   [valve, path, second, side, vessel, each, hose...   \n",
              "2   [accumulator, cell, vehicle, purpose, dispense...   \n",
              "3   [charging, second, transfer, vehicle, module, ...   \n",
              "4   [liquefied, cell, stack, electrochemical, ship...   \n",
              "5   [value, amount, volume, vehicle, sensor, step,...   \n",
              "6   [accumulator, cylinder, line, refrigerant, coo...   \n",
              "7   [pump, engine, passage, injector, vaporizer, o...   \n",
              "8   [cell, main, valve, reducing, energy, stop, se...   \n",
              "9   [charging, cooling, freezing, charged, couplin...   \n",
              "10  [compression, piston, cylinder, hydraulic, com...   \n",
              "11  [information, charging, cooling, step, lubrica...   \n",
              "12  [bank, constant, banks, inspection, regulator,...   \n",
              "13  [electric, charging, energy, particularly, ele...   \n",
              "14  [gaseous, cryogenic, liquefied, vaporization, ...   \n",
              "\n",
              "                                  Representative_Docs  \n",
              "0   [an expansion turbine/compressor high-pressure...  \n",
              "1   [provided is valve which can be easily assembl...  \n",
              "2   [the purpose of the present invention is to pr...  \n",
              "3   [at least two branch transfer of which one end...  \n",
              "4   [fuel supply system for ship is disclosed acco...  \n",
              "5   [to provide gas filling method in which it is ...  \n",
              "6   [an object of the present invention is to supp...  \n",
              "7   [the purpose of the present invention is to su...  \n",
              "8   [the present invention relates to fuel cell sy...  \n",
              "9   [disclosed is an for preventing hydrogen charg...  \n",
              "10  [the present invention relates to hydraulic hy...  \n",
              "11  [the present invention relates to hydrogen sta...  \n",
              "12  [the present invention relates to method for i...  \n",
              "13  [the present invention relates to self-standin...  \n",
              "14  [gaseous hydrogen and distribution system with...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc18e0af-e70a-4cd5-a109-45c2dc84d4dd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic</th>\n",
              "      <th>Count</th>\n",
              "      <th>Name</th>\n",
              "      <th>Representation</th>\n",
              "      <th>Representative_Docs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>59</td>\n",
              "      <td>-1_expansion_ti_turbine_transfer</td>\n",
              "      <td>[expansion, ti, turbine, transfer, least, valv...</td>\n",
              "      <td>[an expansion turbine/compressor high-pressure...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>114</td>\n",
              "      <td>0_valve_path_second_side</td>\n",
              "      <td>[valve, path, second, side, vessel, each, hose...</td>\n",
              "      <td>[provided is valve which can be easily assembl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>1_accumulator_cell_vehicle_purpose</td>\n",
              "      <td>[accumulator, cell, vehicle, purpose, dispense...</td>\n",
              "      <td>[the purpose of the present invention is to pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>68</td>\n",
              "      <td>2_charging_second_transfer_vehicle</td>\n",
              "      <td>[charging, second, transfer, vehicle, module, ...</td>\n",
              "      <td>[at least two branch transfer of which one end...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>56</td>\n",
              "      <td>3_liquefied_cell_stack_electrochemical</td>\n",
              "      <td>[liquefied, cell, stack, electrochemical, ship...</td>\n",
              "      <td>[fuel supply system for ship is disclosed acco...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4</td>\n",
              "      <td>53</td>\n",
              "      <td>4_value_amount_volume_vehicle</td>\n",
              "      <td>[value, amount, volume, vehicle, sensor, step,...</td>\n",
              "      <td>[to provide gas filling method in which it is ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5</td>\n",
              "      <td>50</td>\n",
              "      <td>5_accumulator_cylinder_line_refrigerant</td>\n",
              "      <td>[accumulator, cylinder, line, refrigerant, coo...</td>\n",
              "      <td>[an object of the present invention is to supp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6</td>\n",
              "      <td>39</td>\n",
              "      <td>6_pump_engine_passage_injector</td>\n",
              "      <td>[pump, engine, passage, injector, vaporizer, o...</td>\n",
              "      <td>[the purpose of the present invention is to su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7</td>\n",
              "      <td>38</td>\n",
              "      <td>7_cell_main_valve_reducing</td>\n",
              "      <td>[cell, main, valve, reducing, energy, stop, se...</td>\n",
              "      <td>[the present invention relates to fuel cell sy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>34</td>\n",
              "      <td>8_charging_cooling_freezing_charged</td>\n",
              "      <td>[charging, cooling, freezing, charged, couplin...</td>\n",
              "      <td>[disclosed is an for preventing hydrogen charg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>9</td>\n",
              "      <td>32</td>\n",
              "      <td>9_compression_piston_cylinder_hydraulic</td>\n",
              "      <td>[compression, piston, cylinder, hydraulic, com...</td>\n",
              "      <td>[the present invention relates to hydraulic hy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>10</td>\n",
              "      <td>26</td>\n",
              "      <td>10_information_charging_cooling_step</td>\n",
              "      <td>[information, charging, cooling, step, lubrica...</td>\n",
              "      <td>[the present invention relates to hydrogen sta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>11</td>\n",
              "      <td>25</td>\n",
              "      <td>11_bank_constant_banks_inspection</td>\n",
              "      <td>[bank, constant, banks, inspection, regulator,...</td>\n",
              "      <td>[the present invention relates to method for i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>12</td>\n",
              "      <td>22</td>\n",
              "      <td>12_electric_charging_energy_particularly</td>\n",
              "      <td>[electric, charging, energy, particularly, ele...</td>\n",
              "      <td>[the present invention relates to self-standin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>13</td>\n",
              "      <td>21</td>\n",
              "      <td>13_gaseous_cryogenic_liquefied_vaporization</td>\n",
              "      <td>[gaseous, cryogenic, liquefied, vaporization, ...</td>\n",
              "      <td>[gaseous hydrogen and distribution system with...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc18e0af-e70a-4cd5-a109-45c2dc84d4dd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fc18e0af-e70a-4cd5-a109-45c2dc84d4dd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fc18e0af-e70a-4cd5-a109-45c2dc84d4dd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3885d2fb-0f3b-4620-a9be-2b505bd6a862\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3885d2fb-0f3b-4620-a9be-2b505bd6a862')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3885d2fb-0f3b-4620-a9be-2b505bd6a862 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"full['model']\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Topic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": -1,\n        \"max\": 13,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          8,\n          10,\n          -1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26,\n        \"min\": 21,\n        \"max\": 114,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          34,\n          26,\n          59\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"8_charging_cooling_freezing_charged\",\n          \"10_information_charging_cooling_step\",\n          \"-1_expansion_ti_turbine_transfer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Representation\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Representative_Docs\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model.get_topic_info().to_excel(f'./topic_result_AI요약.xlsx')"
      ],
      "metadata": {
        "id": "ItrwxlPWe3Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_model.visualize_hierarchy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "i8Al4Y9dIkCn",
        "outputId": "0730fc08-6a94-49f6-afad-b6ba7405d558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"4da7f30c-b328-4054-b0df-80da193086fc\" class=\"plotly-graph-div\" style=\"height:410px; width:1000px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4da7f30c-b328-4054-b0df-80da193086fc\")) {                    Plotly.newPlot(                        \"4da7f30c-b328-4054-b0df-80da193086fc\",                        [{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(61,153,112)\"},\"mode\":\"lines\",\"x\":[0.0,0.503146189361869,0.503146189361869,0.0],\"xaxis\":\"x\",\"y\":[-15.0,-15.0,-25.0,-25.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(61,153,112)\"},\"mode\":\"lines\",\"x\":[0.0,0.6045843516244098,0.6045843516244098,0.0],\"xaxis\":\"x\",\"y\":[-35.0,-35.0,-45.0,-45.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(61,153,112)\"},\"mode\":\"lines\",\"x\":[0.503146189361869,0.6874354862866424,0.6874354862866424,0.6045843516244098],\"xaxis\":\"x\",\"y\":[-20.0,-20.0,-40.0,-40.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(61,153,112)\"},\"mode\":\"lines\",\"x\":[0.0,0.7771419648857706,0.7771419648857706,0.6874354862866424],\"xaxis\":\"x\",\"y\":[-5.0,-5.0,-30.0,-30.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(61,153,112)\"},\"mode\":\"lines\",\"x\":[0.0,0.5034335714055218,0.5034335714055218,0.0],\"xaxis\":\"x\",\"y\":[-65.0,-65.0,-75.0,-75.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(61,153,112)\"},\"mode\":\"lines\",\"x\":[0.0,0.5314503396288294,0.5314503396288294,0.0],\"xaxis\":\"x\",\"y\":[-85.0,-85.0,-95.0,-95.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(61,153,112)\"},\"mode\":\"lines\",\"x\":[0.5034335714055218,0.6374077979434305,0.6374077979434305,0.5314503396288294],\"xaxis\":\"x\",\"y\":[-70.0,-70.0,-90.0,-90.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(61,153,112)\"},\"mode\":\"lines\",\"x\":[0.0,0.7095685273269013,0.7095685273269013,0.6374077979434305],\"xaxis\":\"x\",\"y\":[-55.0,-55.0,-80.0,-80.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(61,153,112)\"},\"mode\":\"lines\",\"x\":[0.0,0.748398548352009,0.748398548352009,0.0],\"xaxis\":\"x\",\"y\":[-105.0,-105.0,-115.0,-115.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(61,153,112)\"},\"mode\":\"lines\",\"x\":[0.7095685273269013,0.8100057258599597,0.8100057258599597,0.748398548352009],\"xaxis\":\"x\",\"y\":[-67.5,-67.5,-110.0,-110.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(61,153,112)\"},\"mode\":\"lines\",\"x\":[0.0,0.5712935635533969,0.5712935635533969,0.0],\"xaxis\":\"x\",\"y\":[-125.0,-125.0,-135.0,-135.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(61,153,112)\"},\"mode\":\"lines\",\"x\":[0.8100057258599597,0.9180735577090007,0.9180735577090007,0.5712935635533969],\"xaxis\":\"x\",\"y\":[-88.75,-88.75,-130.0,-130.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(61,153,112)\"},\"mode\":\"lines\",\"x\":[0.7771419648857706,0.9737821040850708,0.9737821040850708,0.9180735577090007],\"xaxis\":\"x\",\"y\":[-17.5,-17.5,-109.375,-109.375],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"autosize\":false,\"height\":410,\"hovermode\":\"closest\",\"showlegend\":false,\"width\":1000,\"xaxis\":{\"mirror\":\"allticks\",\"rangemode\":\"tozero\",\"showgrid\":false,\"showline\":true,\"showticklabels\":true,\"ticks\":\"outside\",\"type\":\"linear\",\"zeroline\":false},\"yaxis\":{\"mirror\":\"allticks\",\"rangemode\":\"tozero\",\"showgrid\":false,\"showline\":true,\"showticklabels\":true,\"tickmode\":\"array\",\"ticks\":\"outside\",\"ticktext\":[\"12_electric_charging_energy\",\"8_charging_cooling_freezing\",\"2_charging_second_transfer\",\"10_information_charging_coo...\",\"4_value_amount_volume\",\"11_bank_constant_banks\",\"0_valve_path_second\",\"7_cell_main_valve\",\"1_accumulator_cell_vehicle\",\"5_accumulator_cylinder_line\",\"9_compression_piston_cylinder\",\"6_pump_engine_passage\",\"13_gaseous_cryogenic_liquef...\",\"3_liquefied_cell_stack\"],\"tickvals\":[-5.0,-15.0,-25.0,-35.0,-45.0,-55.0,-65.0,-75.0,-85.0,-95.0,-105.0,-115.0,-125.0,-135.0],\"type\":\"linear\",\"zeroline\":false,\"range\":[-140.0,0.0]},\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"title\":{\"font\":{\"size\":22,\"color\":\"Black\"},\"text\":\"\\u003cb\\u003eHierarchical Clustering\\u003c\\u002fb\\u003e\",\"x\":0.5,\"xanchor\":\"center\",\"yanchor\":\"top\"},\"hoverlabel\":{\"font\":{\"size\":16,\"family\":\"Rockwell\"},\"bgcolor\":\"white\"},\"plot_bgcolor\":\"#ECEFF1\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4da7f30c-b328-4054-b0df-80da193086fc');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_topic['topic']=topic_model.topics_\n",
        "df_topic.to_excel(f'./압력기반공급제어_토픽.xlsx',index=False)"
      ],
      "metadata": {
        "id": "KQ2WKRsnxsYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyrIzioRiqpy",
        "outputId": "e63795fc-053f-44e1-85d4-6e50bbdf70ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-10-04 14:39:41,205 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n"
          ]
        }
      ],
      "source": [
        "# Method 3 - pickle\n",
        "full['model'].save(\"/content/drive/MyDrive/Patent analysis/ETRI/Model_AI요약\", serialization=\"pickle\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_topic"
      ],
      "metadata": {
        "id": "NYSVScEAzNIh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "y-SQ25ZnqyFh",
        "_1KYcw_mqg0n"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}